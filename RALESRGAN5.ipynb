{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadfar-ha/3GPPDecoder/blob/master/RALESRGAN5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elzKAJfQSRYo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as n\n",
        "import torch.nn.functional as f\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm_notebook,tqdm\n",
        "import cv2\n",
        "import torchvision.utils as vutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7weRVBEySXqI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-dF6InmSZHN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9TS-HgwSakJ"
      },
      "outputs": [],
      "source": [
        "def downloadSampling(img):\n",
        "    image = np.array(img)\n",
        "    image_blur = cv2.resize(image,(64,64),cv2.INTER_CUBIC)\n",
        "    new_image = Image.fromarray(image_blur)\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oruTMS3Sb16"
      },
      "outputs": [],
      "source": [
        "HR_transform = transforms.Compose([\n",
        "                                 transforms.Resize((256,256)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                ])\n",
        "LR_transform = transforms.Compose([\n",
        "                                   transforms.Resize((256,256)),\n",
        "                                   transforms.Lambda(downloadSampling),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naWcMuKRSdeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "7f2daac9e46d4caea321956dcccf4447",
            "e3c52aab2fe14d0e80444c460696863b",
            "15b558fc8ed74613b6b48c65da8ab371",
            "eefce78984fc460fb940363e2d0e1aeb",
            "a7070edf64284e9b8b2b9be7f8129324",
            "cec3e086616645ac86525aa5e92a61d2",
            "ec12cdd00b9e4b0ea6014561d2b11aec",
            "77a27d5226fd4df3ac4ec11931bc7c83",
            "8a2404a4694c4be6bff12e1956d3e19c",
            "d5a24aa1cc01428e869bec59d07c5334",
            "a50e4a1d61fc418c83578f555f1a2070"
          ]
        },
        "outputId": "cff78201-f293-457d-8e6b-9693a4681f9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f2daac9e46d4caea321956dcccf4447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: celebA/celeba/list_attr_celeba.txt\n",
            "Using downloaded and verified file: celebA/celeba/identity_CelebA.txt\n",
            "Using downloaded and verified file: celebA/celeba/list_bbox_celeba.txt\n",
            "Using downloaded and verified file: celebA/celeba/list_landmarks_align_celeba.txt\n",
            "Using downloaded and verified file: celebA/celeba/list_eval_partition.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-39d4cd808cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#imagenet_data = torchvision.datasets.CelebA(root = \"celebA\", download = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mLR_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCelebA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"celebA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHR_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#LR_train_dataset = datasets.ImageFolder(root = \"/content/drive/MyDrive/celebA2\",transform = LR_transform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mLR_train_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/celeba.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/celeba.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mdownload_file_from_google_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"img_align_celeba.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mextract_archive\u001b[0;34m(from_path, to_path, remove_finished)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ARCHIVE_EXTRACTORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marchive_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_extract_zip\u001b[0;34m(from_path, to_path, compression)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_extract_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     with zipfile.ZipFile(\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mfrom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_ZIP_COMPRESSION_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     ) as zip:\n\u001b[1;32m    286\u001b[0m         \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataloader import T\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "#imagenet_data = torchvision.datasets.CelebA(root = \"celebA\", download = True)\n",
        "LR_train_dataset = datasets.CelebA(root = \"celebA\",transform = HR_transform, download = True)\n",
        "#LR_train_dataset = datasets.ImageFolder(root = \"/content/drive/MyDrive/celebA2\",transform = LR_transform)\n",
        "LR_train_dataloader = DataLoader(LR_train_dataset, batch_size = 50)\n",
        "HR_train_dataset = datasets.CelebA(root = \"celebA\",transform = HR_transform, download = False)\n",
        "#HR_train_dataset = datasets.ImageFolder(root = \"/content/drive/MyDrive/celebA2\",transform = HR_transform)\n",
        "HR_train_dataloader = DataLoader(HR_train_dataset, batch_size = 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "!python utils.p"
      ],
      "metadata": {
        "id": "d_91FMpXHj4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06vEtm7kSfcC"
      },
      "outputs": [],
      "source": [
        "HR_batch = next(iter(HR_train_dataloader))\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(HR_batch[0].to(device)[:8], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCl2bdY9Shst"
      },
      "outputs": [],
      "source": [
        "LR_batch = next(iter(LR_train_dataloader))\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(LR_batch[0].to(device)[:8], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7bZShibSjT0"
      },
      "outputs": [],
      "source": [
        "vgg = models.vgg19(pretrained=True).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jYRj8uYSlEm"
      },
      "outputs": [],
      "source": [
        "class ResidualDenseBlock(n.Module):\n",
        "    def __init__(self,in_channel = 64,inc_channel = 32, beta = 0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = n.Conv2d(in_channel, inc_channel, 3, 1, 1)\n",
        "        self.conv2 = n.Conv2d(in_channel + inc_channel, inc_channel, 3, 1, 1)\n",
        "        self.conv3 = n.Conv2d(in_channel + 2 * inc_channel, inc_channel, 3, 1, 1)\n",
        "        self.conv4 = n.Conv2d(in_channel + 3 * inc_channel, inc_channel, 3, 1, 1)\n",
        "        self.conv5 = n.Conv2d(in_channel + 4 * inc_channel,  in_channel, 3, 1, 1)\n",
        "        self.lrelu = n.LeakyReLU()\n",
        "        self.b = beta\n",
        "        \n",
        "    def forward(self, x):\n",
        "        block1 = self.lrelu(self.conv1(x))\n",
        "        block2 = self.lrelu(self.conv2(torch.cat((block1, x), dim = 1)))\n",
        "        block3 = self.lrelu(self.conv3(torch.cat((block2, block1, x), dim = 1)))\n",
        "        block4 = self.lrelu(self.conv4(torch.cat((block3, block2, block1, x), dim = 1)))\n",
        "        out = self.conv5(torch.cat((block4, block3, block2, block1, x), dim = 1))\n",
        "        \n",
        "        return x + self.b * out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhbq77wYSmtQ"
      },
      "outputs": [],
      "source": [
        "class ResidualInResidualDenseBlock(n.Module):\n",
        "    def __init__(self, in_channel = 64, out_channel = 32, beta = 0.2):\n",
        "        super().__init__()\n",
        "        self.RDB = ResidualDenseBlock(in_channel, out_channel)\n",
        "        self.b = beta\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.RDB(x)\n",
        "        out = self.RDB(out)\n",
        "        out = self.RDB(out)\n",
        "        \n",
        "        return x + self.b * out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuiIuwu4SodS"
      },
      "outputs": [],
      "source": [
        "class Generator(n.Module):\n",
        "    def __init__(self,in_channel = 3, out_channel = 3, noRRDBBlock = 23):\n",
        "        super().__init__()   \n",
        "        self.conv1 = n.Conv2d(3, 64, 3, 1, 1)\n",
        "\n",
        "        RRDB = ResidualInResidualDenseBlock()\n",
        "        RRDB_layer = []\n",
        "        for i in range(noRRDBBlock):\n",
        "            RRDB_layer.append(RRDB)\n",
        "        self.RRDB_block =  n.Sequential(*RRDB_layer)\n",
        "\n",
        "        self.RRDB_conv2 = n.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.upconv = n.Conv2d(64, 64, 3, 1, 1)\n",
        "\n",
        "        self.out_conv = n.Conv2d(64, 3, 3, 1, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        first_conv = self.conv1(x)\n",
        "        RRDB_full_block = torch.add(self.RRDB_conv2(self.RRDB_block(first_conv)),first_conv)\n",
        "        upconv_block1 = self.upconv(f.interpolate(RRDB_full_block, scale_factor = 2))\n",
        "        upconv_block2 = self.upconv(f.interpolate(upconv_block1, scale_factor = 2))\n",
        "        out = self.out_conv(upconv_block2)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne7s99zpSp_H"
      },
      "outputs": [],
      "source": [
        "gen = Generator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB2L3YajSrrb"
      },
      "outputs": [],
      "source": [
        "class Discriminator(n.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = n.Conv2d(3,64,3,padding=1,bias=False)\n",
        "        self.conv2 = n.Conv2d(64,64,3,stride=2,padding=1,bias=False)\n",
        "        self.bn2 = n.BatchNorm2d(64)\n",
        "        self.conv3 = n.Conv2d(64,128,3,padding=1,bias=False)\n",
        "        self.bn3 = n.BatchNorm2d(128)\n",
        "        self.conv4 = n.Conv2d(128,128,3,stride=2,padding=1,bias=False)\n",
        "        self.bn4 = n.BatchNorm2d(128)\n",
        "        self.conv5 = n.Conv2d(128,256,3,padding=1,bias=False)\n",
        "        self.bn5 = n.BatchNorm2d(256)\n",
        "        self.conv6 = n.Conv2d(256,256,3,stride=2,padding=1,bias=False)\n",
        "        self.bn6 = n.BatchNorm2d(256)\n",
        "        self.conv7 = n.Conv2d(256,512,3,padding=1,bias=False)\n",
        "        self.bn7 = n.BatchNorm2d(512)\n",
        "        self.conv8 = n.Conv2d(512,512,3,stride=2,padding=1,bias=False)\n",
        "        self.bn8 = n.BatchNorm2d(512)\n",
        "        self.fc1 = n.Linear(512*16*16,1024)\n",
        "        self.fc2 = n.Linear(1024,1)\n",
        "        self.drop = n.Dropout2d(0.3)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        block1 = f.leaky_relu(self.conv1(x))\n",
        "        block2 = f.leaky_relu(self.bn2(self.conv2(block1)))\n",
        "        block3 = f.leaky_relu(self.bn3(self.conv3(block2)))\n",
        "        block4 = f.leaky_relu(self.bn4(self.conv4(block3)))\n",
        "        block5 = f.leaky_relu(self.bn5(self.conv5(block4)))\n",
        "        block6 = f.leaky_relu(self.bn6(self.conv6(block5)))\n",
        "        block7 = f.leaky_relu(self.bn7(self.conv7(block6)))\n",
        "        block8 = f.leaky_relu(self.bn8(self.conv8(block7)))\n",
        "        block8 = block8.view(-1,block8.size(1)*block8.size(2)*block8.size(3))\n",
        "        block9 = f.leaky_relu(self.fc1(block8))\n",
        "#         block9 = block9.view(-1,block9.size(1)*block9.size(2)*block9.size(3))\n",
        "        block10 = torch.sigmoid(self.drop(self.fc2(block9)))\n",
        "        return block9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9Tkn_OuStTg"
      },
      "outputs": [],
      "source": [
        "disc = Discriminator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZNRtMCuSu2B"
      },
      "outputs": [],
      "source": [
        "gen_optimizer = optim.Adam(gen.parameters(),lr=0.0002)\n",
        "disc_optimizer = optim.Adam(disc.parameters(),lr=0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzW46GQCSweu"
      },
      "outputs": [],
      "source": [
        "class Losses():\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.disc_losss = n.BCEWithLogitsLoss()\n",
        "        self.gen_losss = n.BCEWithLogitsLoss()\n",
        "        self.vgg_loss = n.MSELoss()\n",
        "        self.mse_loss = n.MSELoss()\n",
        "        self.lamda = 0.005\n",
        "        self.eeta = 0.02 \n",
        "        \n",
        "    def calculateLoss(self,discriminator, generator,LR_image, HR_image):\n",
        "\n",
        "        disc_optimizer.zero_grad()\n",
        "        generated_output = generator(LR_image.to(device).float())\n",
        "        fake_data = generated_output.clone()\n",
        "        fake_label = discriminator(fake_data)\n",
        "\n",
        "        \n",
        "        HR_image_tensor = HR_image.to(device).float()\n",
        "        real_data = HR_image_tensor.clone()\n",
        "        real_label = discriminator(real_data)\n",
        "        \n",
        "        relativistic_d1_loss = self.disc_losss((real_label - torch.mean(fake_label)), torch.ones_like(real_label, dtype = torch.float))\n",
        "        relativistic_d2_loss = self.disc_losss((fake_label - torch.mean(real_label)), torch.zeros_like(fake_label, dtype = torch.float))      \n",
        "\n",
        "        d_loss = (relativistic_d1_loss + relativistic_d2_loss) / 2\n",
        "        d_loss.backward(retain_graph = True)\n",
        "        disc_optimizer.step()\n",
        "\n",
        "        fake_label_ = discriminator(generated_output)\n",
        "        real_label_ = discriminator(real_data)\n",
        "        gen_optimizer.zero_grad()\n",
        "\n",
        "        g_real_loss = self.gen_losss((fake_label_ - torch.mean(real_label_)), torch.ones_like(fake_label_, dtype = torch.float))\n",
        "        g_fake_loss = self.gen_losss((real_label_ - torch.mean(fake_label_)), torch.zeros_like(fake_label_, dtype = torch.float))\n",
        "        g_loss = (g_real_loss + g_fake_loss) / 2\n",
        "        \n",
        "        v_loss = self.vgg_loss(vgg.features[:6](generated_output),vgg.features[:6](real_data))\n",
        "        m_loss = self.mse_loss(generated_output,real_data)\n",
        "        generator_loss = self.lamda * g_loss + v_loss + self.eeta * m_loss\n",
        "        generator_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        return d_loss,generator_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_wCqCNFSyIy"
      },
      "outputs": [],
      "source": [
        "def loadImages(imageList,path):\n",
        "    images=[]\n",
        "    for image in (imageList):\n",
        "        img = cv2.imread(os.path.join(path,image))\n",
        "        img = np.moveaxis(img, 2, 0)\n",
        "#         print(img.shape)\n",
        "        images.append(img)\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbFNWzeyS0Zd"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "out_path = \"/content/drive/MyDrive/lrrrrr2\"\n",
        "\n",
        "weight_file = \"ESRPT_weights\"\n",
        "if not os.path.exists(weight_file):\n",
        "    os.makedirs(weight_file)\n",
        "\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "test_image_path = os.path.join(os.getcwd(),\"/content/drive/MyDrive/celebA2/test\")\n",
        "images = os.listdir(test_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkHg0mziS2JX"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymTGH4YBS3q6"
      },
      "outputs": [],
      "source": [
        "def imagePostProcess(imagedir,modelPath):\n",
        "    imagelist=[]\n",
        "#     images = os.listdir(imagedir)\n",
        "    for img in imagedir:\n",
        "        img = cv2.resize(cv2.GaussianBlur(cv2.imread(os.path.join(test_image_path,img)),(5,5),cv2.BORDER_DEFAULT),(64,64)) \n",
        "        imagelist.append(img)\n",
        "    imagearray = np.array(imagelist)/255\n",
        "    \n",
        "    imagearrayPT = np.moveaxis(imagearray,3,1)\n",
        "\n",
        "    model = load_checkpoint(modelPath)\n",
        "    im_tensor = torch.from_numpy(imagearrayPT).float()\n",
        "    out_tensor = model(im_tensor)\n",
        "    out = out_tensor.numpy()\n",
        "    out = np.moveaxis(out,1,3)\n",
        "    out = np.clip(out,0,1)\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt-JgQ6ZS5ND"
      },
      "outputs": [],
      "source": [
        "def show_samples(sample_images):\n",
        "    figure, axes = plt.subplots(1, sample_images.shape[0], figsize = (10,10))\n",
        "    for index, axis in enumerate(axes):\n",
        "        axis.axis('off')\n",
        "        image_array = sample_images[index]\n",
        "        axis.imshow(image_array)\n",
        "        image = Image.fromarray((image_array * 255).astype('uint8'))\n",
        "    plt.savefig(os.path.join(os.getcwd(),\"out/SR\")+\"_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06gFWVeRS6p7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook \n",
        "\n",
        "for epoch in (range(1)):\n",
        "    dloss_list=[]\n",
        "    gloss_list=[]\n",
        "    \n",
        "    for data_idx ,(HR_data, LR_data) in tqdm_notebook(enumerate(zip(HR_train_dataloader,LR_train_dataloader)), total = len(LR_train_dataloader)):\n",
        "        HR_data, LR_data = HR_data[0], LR_data[0]\n",
        "        \n",
        "        \n",
        "        disc_loss, gen_loss = Losses().calculateLoss(disc, gen, LR_data, HR_data)\n",
        "        #dloss_list.append(disc_loss.item())\n",
        "        #gloss_list.append(gen_loss.item())\n",
        "        # print(disc_loss, gen_loss)\n",
        "        torch.cuda.empty_cache()\n",
        "#         if(data_idx == 125):\n",
        "#             break\n",
        "\n",
        "    print(\"Epoch ::::  \"+str(epoch+1))\n",
        "    del(disc_loss,gen_loss)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RALESRGAN5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1y5BWr9ApfNLKE1jlwU2pS_9eQiM27KpM",
      "authorship_tag": "ABX9TyMdca9dZr8MtOtZCbfVKMaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f2daac9e46d4caea321956dcccf4447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3c52aab2fe14d0e80444c460696863b",
              "IPY_MODEL_15b558fc8ed74613b6b48c65da8ab371",
              "IPY_MODEL_eefce78984fc460fb940363e2d0e1aeb"
            ],
            "layout": "IPY_MODEL_a7070edf64284e9b8b2b9be7f8129324"
          }
        },
        "e3c52aab2fe14d0e80444c460696863b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec3e086616645ac86525aa5e92a61d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ec12cdd00b9e4b0ea6014561d2b11aec",
            "value": ""
          }
        },
        "15b558fc8ed74613b6b48c65da8ab371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a27d5226fd4df3ac4ec11931bc7c83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a2404a4694c4be6bff12e1956d3e19c",
            "value": 1
          }
        },
        "eefce78984fc460fb940363e2d0e1aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a24aa1cc01428e869bec59d07c5334",
            "placeholder": "​",
            "style": "IPY_MODEL_a50e4a1d61fc418c83578f555f1a2070",
            "value": " 2260/? [00:00&lt;00:00, 40148.78it/s]"
          }
        },
        "a7070edf64284e9b8b2b9be7f8129324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec3e086616645ac86525aa5e92a61d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec12cdd00b9e4b0ea6014561d2b11aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77a27d5226fd4df3ac4ec11931bc7c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8a2404a4694c4be6bff12e1956d3e19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5a24aa1cc01428e869bec59d07c5334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50e4a1d61fc418c83578f555f1a2070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}